{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),'exp'))\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "import datetime\n",
    "import collections\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nb_base_exp import *#BaseExperiment, BaseProject, load_txt_log\n",
    "from config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def load_log(path):\n",
    "    columns = ['date','epoch','acc','val_acc']\n",
    "    types = [str, np.int32, np.float32, np.float32]\n",
    "    log_path = list(path.rglob('*/*/log.txt'))[0]\n",
    "\n",
    "    _, logs = load_txt_log(path=log_path, types=types)\n",
    "\n",
    "    df = pd.DataFrame(logs, columns=columns)\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.astype(dict(zip(columns, types)))\n",
    "\n",
    "    df['val_acc'].replace(-1., np.NaN, inplace=True)\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df.set_index('epoch', inplace=True)\n",
    "    timeDF=(pd.to_datetime(df['date'].str.strip(), format='%H:%M:%S'))\n",
    "    del df['date']# = timeDF\n",
    "    df['duration'] = timeDF - timeDF[0]\n",
    "    return df\n",
    "\n",
    "def load_yaml_cfg(path):\n",
    "    params_path = list(path.rglob('*/*/train.yaml'))[0]\n",
    "    with open(params_path, 'r') as f:\n",
    "        d = yaml.safe_load(f)\n",
    "    d = flatten(d, sep='|')\n",
    "    d = OrderedDict(sorted(d.items(), key=lambda x:x[0], reverse=False))\n",
    "    return d\n",
    "\n",
    "def load_json_cfg(path):\n",
    "    params_path = list(path.rglob('*/*/params.json'))[0]\n",
    "    with open(params_path, 'r') as f:\n",
    "        d = json.load(f)\n",
    "    d = flatten(d, sep='|')\n",
    "    d = OrderedDict(sorted(d.items(), key=lambda x:x[0], reverse=False))\n",
    "    return d\n",
    "\n",
    "def load_cfg(*args, **kwargs):\n",
    "    return load_json_cfg(*args, **kwargs)\n",
    "\n",
    "def check_valid(cpath):\n",
    "    flag_files = set(['log.txt', 'params.json'])\n",
    "    where_to_look = 'output'\n",
    "    output = list(Path(cpath).rglob(where_to_look))\n",
    "    files=[]\n",
    "    if output:\n",
    "        files = list(output[0].glob('*/*'))\n",
    "\n",
    "    return flag_files.issubset(set([f.name for f in files]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class GenExperiment(BaseExperiment):\n",
    "    def __init__(self,  path):\n",
    "        super(GenExperiment, self).__init__(path, log_reader=load_log, cfg_reader=load_cfg)\n",
    "        self.start_time = self.parse_name()\n",
    "\n",
    "    def parse_name(self, prefix='run_'):\n",
    "        date = self.name.strip(prefix)#.rstrip('.lock')\n",
    "        start_time = datetime.datetime.strptime(date, '%Y_%b_%d_%H_%M_%S_%f')\n",
    "        return start_time\n",
    "\n",
    "    def total_time(self):\n",
    "        return self.log_data['duration'][self.__len__()-1]\n",
    "    \n",
    "class GenProject(BaseProject):\n",
    "    def __init__(self,  root):\n",
    "        super(GenProject, self).__init__(root, valid_func=check_valid, Experiment=GenExperiment)\n",
    "    \n",
    "    def extend_base(self):\n",
    "        dd = {}\n",
    "        for run in self.exps:\n",
    "            run_best = run.best(num=3, col='val_acc')\n",
    "            #run_best_pct = 100 - int( 100 * (run.total_time() - dur) / run.total_time())\n",
    "            d = {}\n",
    "            d['start'] = run.start_time\n",
    "            d['name'] = run.name\n",
    "            d['tt'] = run.total_time()\n",
    "            d['t2b'] = run_best['duration'].values[0]\n",
    "            d['ba'] = round(run_best.mean()[['acc']].values[0],3)\n",
    "            d['bva'] = round(run_best.mean()[['val_acc']].values[0],3)\n",
    "            d['la'] = round(run.log_data['acc'][-10:].mean(),3)\n",
    "            #d.update(**run.params)\n",
    "            dd[run.name] = d\n",
    "        #res_df = pd.DataFrame(results, columns=['Name','duration', 'LRM', 'best_acc', 'best_val', 'best_pct', *run.params.keys()])\n",
    "\n",
    "        df = pd.DataFrame(dd).T\n",
    "        df = pd.concat([df,self.base_table()], axis=1)\n",
    "        df.set_index('start', drop=True, inplace=True)\n",
    "#         for x in ['tt','t2b']:\n",
    "#             df[x] = pd.DatetimeIndex(df[x]).strftime(\"%H:%M:%S\")\n",
    "            \n",
    "        df['ba'] = df['ba'].astype(float)\n",
    "        df['la'] = df['la'].astype(float)\n",
    "        df['bva'] = df['bva'].astype(float)\n",
    "        df = df.round(4)\n",
    "        \n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot(cols=None, window=1,limits=[-1,-1], ax=None, x=None):\n",
    "        if ax is None:\n",
    "            f,ax = plt.subplots(1)\n",
    "        if cols is None:\n",
    "            cols = ['acc']\n",
    "        if x is not None:\n",
    "            cols.append(x)\n",
    "            \n",
    "        data = e.log_data\n",
    "        llim, rlim = limits\n",
    "        rlim = len(data) if rlim <=0 else rlim\n",
    "        llim = max(0, llim)\n",
    "        \n",
    "        \n",
    "        d = data.iloc[llim:rlim,:]\n",
    "        d = d.loc[:,cols]\n",
    "        for c in cols:\n",
    "            if c != 'duration':\n",
    "                d[c] = d[c].rolling(window).mean() \n",
    "        \n",
    "        d.plot(figsize=(12,7), ax=ax, x=x)\n",
    "        \n",
    "def mod_df(df, col='acc', window=1, div=1):\n",
    "    d = df.loc[:, [col, 'duration']]\n",
    "    s = d['duration'].apply(lambda x: x.seconds)/div\n",
    "    d.loc[:,'duration'] = s\n",
    "    \n",
    "    s = d[col].rolling(window).mean()\n",
    "    d.loc[:,col] = s\n",
    "    return d\n",
    "\n",
    "def plot_run(run, col, ax,  window=5):\n",
    "    d = mod_df(run.log_data, col=col, window=window)\n",
    "    d.plot('duration', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(cfg.DAG.RUNS)\n",
    "#root = Path('../__crsch_cycle/cycler_runs/')\n",
    "\n",
    "bp = GenProject(root)\n",
    "df = bp.extend_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.sort_index(ascending=False).head(5)\n",
    "df.drop(['name'], axis=1).sort_values('bva', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df['bva']\n",
    "print(s.mean())\n",
    "s = s.sort_index()\n",
    "plt.plot(s.rolling(3).mean().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tt'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['ba']>.3]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['crossover_chance']==1.99]\n",
    "# df.shape\n",
    "# names = df.sort_index()['name'][:30].values\n",
    "# p = Path('../__crsch_cycle/cycler_runs/')\n",
    "# for name in names:\n",
    "#     pi = p/name\n",
    "#     shutil.rmtree(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 'bva'\n",
    "tdf = df.sort_index(ascending=False)#[:80]\n",
    "fig = px.parallel_coordinates(tdf, color=k,\n",
    "              dimensions=['genom|combine_chance', 'genom|crossover_chance', 'genom|mutate_chance', 'post|exp_power',\n",
    "                         #'dec_f0','dec_f1','dec_f2','dec_f3',\n",
    "                          'bva'],\n",
    "              color_continuous_scale=px.colors.diverging.Tealrose,\n",
    "              range_color=[0.45,df[k].max()],\n",
    "              color_continuous_midpoint=.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = df[:1]\n",
    "top = df.sort_values(by='bva', ascending=False)[16:18]\n",
    "plot_df = pd.concat([plot_df,top])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = bp.exps\n",
    "f, a = plt.subplots(1, figsize=(15,8))\n",
    "#l_lim, r_lim = 0, 1000\n",
    "\n",
    "rsp = [r for r in rs if r.name in plot_df.name.values]\n",
    "\n",
    "[plot_run(r, col='acc', ax=a, window=25) for r in rsp]\n",
    "\n",
    "a.legend([r.name for r in rsp])\n",
    "#a.legend(['logs'])\n",
    "\n",
    "#a.set_xticks(np.arange(l_lim, 700, 10))\n",
    "#a.set_yticks(np.arange(0.1, .9, 0.05))\n",
    "plt.ylim(0.0,.6)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('./results/bo3/')\n",
    "bp = GenProject(root)\n",
    "df = bp.extend_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('bva', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperSet:\n",
    "    def  __init__(self, cfg, param_list, target):\n",
    "        self.cfg = cfg\n",
    "        self.params = param_list\n",
    "        self.target = target\n",
    "        \n",
    "    def read_cfg(self, map_names):\n",
    "        if map_names is None: map_names = {p:p for p in self.params}\n",
    "            \n",
    "        points = {}\n",
    "        for p in self.params:\n",
    "            p_mapped = map_names[p]\n",
    "            points[p_mapped] = self.cfg[p]\n",
    "        return points\n",
    "    \n",
    "    def create_record(self, map_names=None):\n",
    "        return {\n",
    "            'points':self.read_cfg(map_names),\n",
    "            'target':self.target\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_e = bp.exps[0]\n",
    "base_e.cfg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.nb_base_exp import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [('TRAIN|DS', ['data1']), ('TRAIN|LR',1e-5), ('MODEL|ARCH|n1', 8)]\n",
    "sep = '|'\n",
    "\n",
    "d = {}\n",
    "for p in pairs:\n",
    "    di = create_nested(defaultdict(dict), *p)\n",
    "    dict_merge(d, di)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train.yaml', 'r') as f:\n",
    "    d = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_d = flatten(d, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, v = list(flat_d.items())[17]\n",
    "k, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train_mod.yaml', 'w') as f:\n",
    "    yaml.safe_dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_params = ['combine_chance', 'crossover_chance', 'mutate_chance']\n",
    "lat_names = ['cc', 'cr','mc']\n",
    "map_names = dict(zip(bo_params,lat_names))\n",
    "\n",
    "bo_target = 'val_acc'\n",
    "\n",
    "hps = []\n",
    "for e in bp.exps:\n",
    "    target = e.log_data[bo_target].max()\n",
    "    cfg = e.cfg_data\n",
    "    hp = HyperSet(cfg, bo_params, target)\n",
    "    rec = hp.create_record(map_names)\n",
    "    hps.append(rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_warm = []\n",
    "for e in bp.exps:\n",
    "    target = e.log_data[bo_target].max()\n",
    "    points = {}\n",
    "    for p in bo_params:\n",
    "        points[p] = e.cfg_data[p]\n",
    "    hp_warm.append({'target': target,\n",
    "                    'points': points})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_warm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 extra/n2s.py gen_exp.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
