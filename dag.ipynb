{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "sys.path.append('/home/sokolov/work/cycler/crsch_cycle/exp/')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from functools import partial\n",
    "from datetime import timedelta\n",
    "from airflow import DAG\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from airflow.utils.dates import days_ago\n",
    "\n",
    "from nb_runner import cycle_exp, cycle_mutate, cycle_crossover, cycle_combine, cycle_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': days_ago(2),\n",
    "    'email': False,\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 0,\n",
    "    'retry_delay': timedelta(minutes=5),}\n",
    "\n",
    "default_pool = 'sokolov_pool_gpu0'\n",
    "\n",
    "dag = DAG(  'crsch_hyp_search1',\n",
    "                default_args=default_args,\n",
    "                description='crossover, mutate, combine chances',\n",
    "                schedule_interval=None)\n",
    "\n",
    "def base_task_generator(name, func, dag, pool=default_pool, op_kwargs=None):\n",
    "    task = PythonOperator(\n",
    "                    task_id=name,\n",
    "                    python_callable=func,\n",
    "                    op_kwargs=op_kwargs,\n",
    "                    provide_context=True,\n",
    "                    pool=pool,\n",
    "                    dag=dag,)\n",
    "    return task\n",
    "\n",
    "create_task = partial(base_task_generator, dag=dag)\n",
    "\n",
    "def pull_results(**context):\n",
    "    upstream_task_results = None\n",
    "    if context is not None:\n",
    "        task = context['task']\n",
    "        upstream_task_ids = task.upstream_task_ids\n",
    "        upstream_task_results = [context['ti'].xcom_pull(task_ids=task_id) for task_id in upstream_task_ids]\n",
    "    \n",
    "    return upstream_task_results\n",
    "\n",
    "def parse_results(upstream_task_results, first=False):\n",
    "    aux_cfg_files, docker_results = None, None\n",
    "    \n",
    "    if upstream_task_results:\n",
    "        aux_cfg_files, docker_results = [],[]\n",
    "        for results in upstream_task_results:\n",
    "            try:\n",
    "                aux_cfg_files.append(results['configs'])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            try:\n",
    "                docker_results.append(results['docker_results'])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    \n",
    "    if first and aux_cfg_files:\n",
    "        aux_cfg_files = aux_cfg_files[0]\n",
    "    \n",
    "    if first and docker_results:\n",
    "        docker_results = docker_results[0]\n",
    "    \n",
    "    return aux_cfg_files, docker_results\n",
    "\n",
    "def parse_pool(pool_str):\n",
    "    return ','.join([i for i in pool_str if i.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dw_cycle_param(func, first=False, **context):\n",
    "    aux_cfg_files, _ = parse_results(pull_results(**context), first=first)\n",
    "    gpus = parse_pool(context['ti'].pool)\n",
    "    return func(aux_cfg_files=aux_cfg_files, gpus=gpus)\n",
    "\n",
    "def dw_cycle_pool(**context):\n",
    "    aux_cfg_files, docker_results = parse_results(pull_results(**context))\n",
    "    idx = np.argmax(docker_results)\n",
    "    print(f'\\n\\tPooling: best result in #{idx}: {docker_results[idx]}, {aux_cfg_files[idx]}\\n')\n",
    "    return {'configs':aux_cfg_files[idx]}\n",
    "\n",
    "def cycle_block(n, name, func):\n",
    "    tasks = []\n",
    "    for i in range(n):\n",
    "        task_name = f'{name}_{i}'\n",
    "        pool = f'sokolov_pool_gpu{i%3}'\n",
    "        func_partial = partial(func, seq_id=i, name=task_name)\n",
    "        task = create_task(task_name, dw_cycle_param, pool=pool, op_kwargs={'func':func_partial, 'first':True}) \n",
    "        tasks.append(task) \n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "tasks = {'mut':[], 'exp':[], 'cross':[]}\n",
    "\n",
    "cycle_block(50, 'cycle_all', cycle_all)\n",
    "#tasks['exp'] = cycle_block(3, 'cycle_e', cycle_exp)\n",
    "\n",
    "# pooling_task1 = create_task(f'pooling1', dw_cycle_pool) \n",
    "# for task in tasks['exp']:\n",
    "#     task >> pooling_task1\n",
    "\n",
    "# tasks['mut'] = cycle_block(10, 'cycle_m', cycle_mutate)\n",
    "# pooling_task2 = create_task(f'pooling2', dw_cycle_pool) \n",
    "# for task in tasks['mut']:\n",
    "#     pooling_task1 >> task\n",
    "#     task >> pooling_task2\n",
    "    \n",
    "# tasks['cross'] = cycle_block(10, 'cycle_cr', cycle_crossover)\n",
    "# pooling_task3 = create_task(f'pooling3', dw_cycle_pool) \n",
    "# for task in tasks['cross']:\n",
    "#     pooling_task2 >> task\n",
    "#     task >> pooling_task3\n",
    "    \n",
    "# tasks['comb'] = cycle_block(10, 'cycle_co', cycle_combine)\n",
    "# for task in tasks['comb']:\n",
    "#     pooling_task3 >> task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.models import TaskInstance\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(**kwargs):\n",
    "    pprint(kwargs)\n",
    "    return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = base_task_generator('test', test, dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'END_DATE': '2020-05-10',\n",
      " 'conf': <airflow.configuration.AirflowConfigParser object at 0x7f204759c1d0>,\n",
      " 'dag': <DAG: crsch_hyp_search1>,\n",
      " 'dag_run': None,\n",
      " 'ds': '2020-05-10',\n",
      " 'ds_nodash': '20200510',\n",
      " 'end_date': '2020-05-10',\n",
      " 'execution_date': <Pendulum [2020-05-10T23:26:41.864886+00:00]>,\n",
      " 'inlets': [],\n",
      " 'latest_date': '2020-05-10',\n",
      " 'macros': <module 'airflow.macros' from '/home/sokolov/.local/lib/python3.6/site-packages/airflow/macros/__init__.py'>,\n",
      " 'next_ds': None,\n",
      " 'next_ds_nodash': None,\n",
      " 'next_execution_date': None,\n",
      " 'outlets': [],\n",
      " 'params': {},\n",
      " 'prev_ds': None,\n",
      " 'prev_ds_nodash': None,\n",
      " 'prev_execution_date': None,\n",
      " 'prev_execution_date_success': <Proxy at 0x7f206fc74e88 with factory <function TaskInstance.get_template_context.<locals>.<lambda> at 0x7f203c545f28>>,\n",
      " 'prev_start_date_success': <Proxy at 0x7f203c8f87c8 with factory <function TaskInstance.get_template_context.<locals>.<lambda> at 0x7f206ffd7268>>,\n",
      " 'run_id': None,\n",
      " 'tables': None,\n",
      " 'task': <Task(PythonOperator): test>,\n",
      " 'task_instance': <TaskInstance: crsch_hyp_search1.test 2020-05-10 23:26:41.864886+00:00 [None]>,\n",
      " 'task_instance_key_str': 'crsch_hyp_search1__test__20200510',\n",
      " 'templates_dict': None,\n",
      " 'test_mode': False,\n",
      " 'ti': <TaskInstance: crsch_hyp_search1.test 2020-05-10 23:26:41.864886+00:00 [None]>,\n",
      " 'tomorrow_ds': '2020-05-11',\n",
      " 'tomorrow_ds_nodash': '20200511',\n",
      " 'ts': '2020-05-10T23:26:41.864886+00:00',\n",
      " 'ts_nodash': '20200510T232641',\n",
      " 'ts_nodash_with_tz': '20200510T232641.864886+0000',\n",
      " 'var': {'json': None, 'value': None},\n",
      " 'yesterday_ds': '2020-05-09',\n",
      " 'yesterday_ds_nodash': '20200509'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti = TaskInstance(task=task, execution_date=datetime.now())\n",
    "task.execute(context=ti.get_template_context())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sokolov_pool_6'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti.pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_state(args):\n",
    "    dag = get_dag(args)\n",
    "    task = dag.get_task(task_id=args.task_id)\n",
    "    ti = TaskInstance(task, args.execution_date)\n",
    "    print(ti.current_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted dag.ipynb to exp/nb_dag.py\n"
     ]
    }
   ],
   "source": [
    "!python3 n2s.py dag.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-05-10 23:59:44,405] {__init__.py:51} INFO - Using executor LocalExecutor\n",
      "[2020-05-10 23:59:44,405] {dagbag.py:396} INFO - Filling up the DagBag from /home/sokolov/airflow/dags\n",
      "[2020-05-10 23:59:44,406] {dagbag.py:396} INFO - Filling up the DagBag from /home/sokolov/work/cycler/crsch_cycle/exp\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "DAGS\n",
      "-------------------------------------------------------------------\n",
      "crsch_hyp_search1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!airflow list_dags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
